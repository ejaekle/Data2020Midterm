choose(8,6)+choose(10,6)+choose(12,6)
1162/593775
choose()
choose(60,5)
choose(5,5)*choose(5,10)/choose(15,10)
choose(5,5)
choose(5,10)
choose(5,5)*choose(10,5)/choose(15,10)
choose(6,10)*choose(8,11)
choose(6,10)
choose(10,6)
choose(5,0)
choose()
choose(0,5)
choose(5,2)
dbinom(6,size = 20,prob = .25)
dhyper(2,6,9,5)
choose(6,5)
choose(9,3)
choose(15,2)
phyper(2,6,9,5)
phyper(1,6,9,5)
choose(6,5)
choose(9,3)
choose(15,5)
dhyper()
dhyper(2,6,9,5)
dhyper(2,6,9,5,log=FALSE)
choose(9,4)
choose(9,5)
load("/Users/emily/Desktop/R/CH07/exe7-01.RData")
View(`exe7-01`)
mean(`exe7-01`$IQ1)
median(`exe7-01`$IQ1)
sd(`exe7-01`$IQ1)
load("/Users/emily/Desktop/R/CH07/exe7-03.RData")
View(`exe7-03`)
mean(`exe7-03`$thick)
median(`exe7-03`$thick)
sd(`exe7-03`$thick)
qchisq(.005,df=10)
qf(c(.005,.995),df=10)
qf(c(.01,1)df=10)
qf(.01,1,10)
qf(10.4,1,10)
qf(.99,1,10)
qf(.99,2,4)
qf(.9,2,4)
load("/Users/emily/Desktop/R/CH08/exe8-47.RData")
View(`exe8-47`)
qqnorm(`exe8-47`$time)
load("/Users/emily/Desktop/R/CH08/exe8-33.RData")
View(`exe8-33`)
View(`exe8-33`)
qqnorm(`exe8-33`$temp)
mean(`exe8-33`$temp)
sd(`exe8-33`$temp)
mean(`exe8-47`$time)
sd(`exe8-47`$time)
qt(.995,df=9)
qt(.025,df=9)
qt(.975,df=9)
qt(.95,df=13)
qt(.95,df=25)
qt(.975,df=24)
load("/Users/emily/Desktop/R/CH08/exe8-41.RData")
View(`exe8-41`)
mean(`exe8-41`$length)
sd(`exe8-41`$length)
qt(.975,df=62)
qqnorm((`exe8-41`$length))
load("/Users/emily/Desktop/R/CH08/exe8-49.RData")
View(`exe8-49`)
mean(`exe8-49$hours)
v
mean(`exe8-49'$hours)
mean(`exe8-49`$hours)
sd(`exe8-49`$hours)
qt(.975,df=21)
install.packages("boot")
y = c(`exe8-49`$hours)
tips = data.frame(y)
tips.ts.f <- function(data, i){
d <- data[i]
m <- mean(d)
m }
tips.ts.boot <- boot(y,tips.ts.f,R=999)
install.packages("boot")
library(boot)
y = c(`exe8-49`$hours)
load("/Users/emily/Desktop/R/CH08/exe8-49.RData")
View(`exe8-49`)
y = c(`exe8-49`$hours)
tips = data.frame(y)
tips.ts.f <- function(data, i){
d <- data[i]
m <- median(d)
m }
tips.ts.boot <- boot(y,tips.ts.f,R=999)
bin(7,25,.5)
qbinom(7,25,.5)
qbinom(.5,25,7)
pbinom(7,25,.5)
pbinom(17,25,.5)
pbinom(17,25,.4)
pbinom(8,25,.5)
> pbinom(8,25,.4)
pbinom(8,25,.4)
pbimon(17,25.4)-pbinom(8,25,.4)
pbinom(17,25.4)-pbinom(8,25,.4)
> pbinom(17,25,.4)-pbinom(8,25,.4)
pbinom(17,25,.4)-pbinom(8,25,.4)
pbinom(17,25,.6)-pbinom(8,25,.6)
pbinom(17,25,.4)-pbinom(7,25,.4)
pbinom(17,25,.6)-pbinom(7,25,.6)
binom(17,25,.7)-pbinom(7,25,.7)
pbinom(17,25,.7)-pbinom(7,25,.7)
pbinom(17,25,.3)-pbinom(7,25,.3)
pnorm
pstandardnorm()
pnorm(.08,mean=0,sd=1)
load("/Users/emily/Desktop/R/CH09/exe09-11.RData")
View(`exe09-11`)
mean(`exe09-11`$weight)
mean(`exe09-11`$Weight)
pt(-1.759)
pnorm(0)
pnorm(-3.714285714)
pbinom(5,10,.9)
pbinom(6,10,.9)
pbinom(0,10,.9)
pbinom(0,10,.9)+1-pbinom(9,10,.9)
pbinom(1,10,.9)+1-pbinom(8,10,.9)
pbinom(2,10,.9)+1-pbinom(7,10,.9)
pbinom(8,10,.9)+1-pbinom(1,10,.9)
pbinom(3,10,.9)+1-pbinom(6,10,.9)
pbinom(4,10,.9)+1-pbinom(5,10,.9)
pbinom(5,10,.9)+1-pbinom(4,10,.9)
pnorm(3.714285714)
pbinom(5,10,.9)+1-pbinom(4,10,.9)
qf(.95,2,8)
qf(.95,2,21)
pf(1.7,3,16)
load("/Users/emily/Downloads/Chapter+11%2C+Exercise+42.RData")
View(`exe11-42`)
summary(aov.out)
plot(TukeyHSD(aov.out,which=subject))
plot(TukeyHSD(aov.out,which=stool))
plot(TukeyHSD(aov.out,which="stool"))
plot(TukeyHSD(aov.out,which="subject"))
plot(TukeyHSD(aov.out,which="stool"))
qt(.975,13)
qt(.975,9)
pt(-.226,9)
qt(.9995,12)
qt(.975,12)
pt(.6,1)
pt(.5,1)
pt(1,.5)
qt(.5,1)
pt(.5,2)
pt(.5,1)
pt(.025,1)
pt(.975,1)
qt(.975,1)
pt(.5,4)
pt(.5,1)
pt(.25,1)
pt(.5,1)
pt(.5,1)
qf(.999,16,186)
pt(10.62,7)
pt(10.62,7)
qt(.975,7)
load("/Users/emily/Desktop/R/CH12/exe12-53.RData")
View(`exe12-53`)
scatter.smooth(`exe12-53`$x,`exe12-53`$y)
plot(`exe12-53`$x,`exe12-53`$y)
plot(`exe12-53`)
scatter.smooth(`exe12-53`)
model<-lm(x~y,data=`exe12-53`)
yfit<-model$fitted.values
summary(model)
lm(x~y,data=`exe12-53`)
summary(lm(x~y,data=`exe12-53`))
pt(-.5,1)
pt(.5,1)
1-pt(.5,1)
qt(.975,13)
load("/Users/emily/Desktop/R/CH12/exe12-17.RData")
View(`exe12-17`)
model<-lm(y~x,data=`exe12-17`)
newdata=data.frame(x=40)
predict(model,newdata,interval = "confidence")
qchisq(.95,4)
qchisq(.99,3)
qchisq(.90,3)
qchisq(.99,5)
qchisq(.95,3)
pchisq(1.57,3)
qchisq(.99,3)
pchisq(4.0345,3)
qexp(.2,1)
qexp(.4,1)
qexp(.6,1)
qexp(.8,1)
2*(1-pnorm(2.27))
qchisq(.9,7)
1-pchisq(4.8,7)
qchisq(.99,3)
1-pchisq(83.225,3)
load("/Users/emily/Desktop/R/Ch13/exe13-40.RData")
View(`exe13-40`)
load("/Users/emily/Desktop/R/CH14/exe14-04.RData")
View(`exe14-04`)
wilcox.test(`exe14-04`$Time,mu=30,alternative = c("less"))
wilcox.test(`exe14-04`$Time,mu=30,alternative = c("greater"))
wilcox.test(`exe14-04`$Time,mu=30)
chisq.test(`exe13-40`[2:4])
qchisq(.9,4)
qchisq(.9,5)
library(tidyverse)
#library(tidyverse)
library(MASS)
library(ISLR)
library(ggfortify)
# View data and summary information
install.packages("tidyverse")
library(tidyverse)
library(MASS)
library(ISLR)
# View data and summary information
library(tidyverse)
library(MASS)
install.packages(ISLR)
library(ISLR)
install.packages(ISLR)
library(ISLR)
# View data and summary information
# fix(Boston)
names(Boston)
?Boston
summary(Boston)
college = read.csv("College.csv")
y <- rbern(100, 0.5)
X <- matrix(rbern(100*10000,0.5), 100, 1000)
# part A
library(simcausal)
y <- rbern(100, 0.5)
X <- matrix(rbern(100*10000,0.5), 100, 1000)
r.squared.values <- vector(length=100)
for (i in 1:100){
linearmodel <- lm(y~X[,i])
r.squared.values[i] <- summary(linearmodel)$r.squared
}
i.star <- which.max(r.squared.values)
i.star
xy.dataframe <- data.frame(y = y, x= X[,i.star])
k = 5
folds = cut(seq(1, nrow(xy.dataframe)), breaks = k, labels=FALSE)
folds = folds[sample(length(folds))]
cv.errors = matrix(NA,k,1)
for (j in 1:k){
lm.fit.1 = lm(y~x, data = xy.dataframe[folds!=j,])
pred.1 = predict(lm.fit.1, xy.dataframe[folds==j,])
cv.errors[j,1] = mean((xy.dataframe$y[folds==j]-pred.1)^2)
}
mean(cv.errors)
for (i in 1:10000){
linearmodel <- lm(y~X[,i])
r.squared.values[i] <- summary(linearmodel)$r.squared
}
linearmodel <- lm(y~X[i,])
r.squared.values <- vector(length=10000)
for (i in 1:10000){
linearmodel <- lm(y~X[i,])
r.squared.values[i] <- summary(linearmodel)$r.squared
}
i.star <- which.max(r.squared.values)
i.star
y <- rbern(100, 0.5)
X <- matrix(rbern(100*10000,0.5), 100, 10000)
r.squared.values <- vector(length=10000)
for (i in 1:10000){
linearmodel <- lm(y~X[,i])
r.squared.values[i] <- summary(linearmodel)$r.squared
}
i.star <- which.max(r.squared.values)
i.star
xy.dataframe <- data.frame(y = y, x= X[,i.star])
k = 5
folds = cut(seq(1, nrow(xy.dataframe)), breaks = k, labels=FALSE)
folds = folds[sample(length(folds))]
cv.errors = matrix(NA,k,1)
for (j in 1:k){
lm.fit.1 = lm(y~x, data = xy.dataframe[folds!=j,])
pred.1 = predict(lm.fit.1, xy.dataframe[folds==j,])
cv.errors[j,1] = mean((xy.dataframe$y[folds==j]-pred.1)^2)
}
mean(cv.errors)
names(nyc_census)
census <- read.csv('nyc_census.csv')
setwd("~/Desktop/data2020/Data2020Midterm")
census <- read.csv('nyc_census.csv')
census <- data.frame(census)
source('~/Desktop/data2020/Data2020Midterm/exploratory.R')
names(nyc_census)
hist(Country)
hist(nyc_census$Country)
hist(nyc_census$Income)
hist(Income)
hist(TotalPop)
hist(Income)
hist(nyc_census$Income)
hist(nyc_census$TotalPop)
hist(nyc_census$IncomePerCap)
View(nyc_census)
hist(nyc_census$County)
location1 <-nyc_census[(nyc_census$Borough=='Brooklyn'),]
View(location1)
View(nyc_census)
View(nyc_census)
brooklyn <- nyc_census[(nyc_census$Borough=='Brooklyn'),]
manhattan <- nyc_census[(nyc_census$Borough=='Manhattan'),]
queens <- nyc_census[(nyc_census$Borough=='Queens'),]
bronx <- nyc_census[(nyc_census$Borough=='Bronx'),]
staten.island <- nyc_census[(nyc_census$Borough=='Staten Island'),]
sum(brooklyn$TotalPop)
sum(manhattan$TotalPop)
sum(queens$TotalPop)
sum(bronx$TotalPop)
sum(staten.island$TotalPop)
(brooklyn$Hispanic)/100
percentages*brooklyn$TotalPop
percentages <- (brooklyn$Hispanic)/100
percentages*brooklyn$TotalPop
sum(percentages*brooklyn$TotalPop)
percentages <- (manhattan$Hispanic)/100
sum(percentages*manhattan$TotalPop)
percentages <- (queens$Hispanic)/100
sum(percentages*queens$TotalPop)
percentages <- (bronx$Hispanic)/100
sum(percentages*bronx$TotalPop)
percentages <- (staten.island$Hispanic)/100
sum(percentages*staten.island$TotalPop)
